{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook analyzes a toughies.csv file. This file is generated by the Django management command named `get_toughie_info.py` with a production db backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toughies = pandas.read_csv('./toughies.csv')\n",
    "len(toughies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For better statistical significance, filter only bingos that were asked at least 30 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_toughies = toughies.loc[toughies['asked'] >= 30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order of dictionary updates:\n",
    "def lexkey_assigner(row):\n",
    "    if row['lexicon'] == 'OWL2':\n",
    "        return 1\n",
    "    elif row['lexicon'] == 'America':\n",
    "        return 2\n",
    "    elif row['lexicon'] == 'NWL18':\n",
    "        return 3\n",
    "\n",
    "better_toughies = better_toughies.assign(\n",
    "    lexkey=better_toughies.apply(lexkey_assigner, axis=1)).sort_values('lexkey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which words have NOT been asked yet. \n",
    "with open('./7s_alphs.csv') as f:\n",
    "    alphas_7s = set([a for a in f.read().split('\\n') if len(a) == 7])\n",
    "\n",
    "with open('./8s_alphs.csv') as f:\n",
    "    alphas_8s = set([a for a in f.read().split('\\n') if len(a) == 8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additions_to_existing_alphagrams(filename) -> dict:\n",
    "    \"\"\" \n",
    "    given the csv file, output a dictionary of alphagrams to words\n",
    "    where at least one of the words in each pair previously existed\n",
    "    in the last dictionary update.\n",
    "    the csv file consists of the added words and alphagrams \n",
    "    in an update.\n",
    "    \"\"\"\n",
    "    alphas = {}\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            tpl = (row['word'], row['added'])\n",
    "            if row['alpha'] not in alphas:\n",
    "                alphas[row['alpha']] = [tpl]\n",
    "            else:\n",
    "                alphas[row['alpha']].append(tpl)\n",
    "    # Now, keep only the ones where the value has at least one non-+ word.\n",
    "    new_alphas = {}\n",
    "    for k, v in alphas.items():\n",
    "        if any([s == '' for _, s in v]):\n",
    "            new_alphas[k] = [w for w, _ in v] \n",
    "    return new_alphas\n",
    "\n",
    "# These text files below were created like:\n",
    "# select word, alphagram, lexicon_symbols from (\n",
    "#      select alphagrams.alphagram from alphagrams where\n",
    "#      contains_update_to_lex=1 and length=7 order by alphagrams.probability) q \n",
    "# inner join words w using (alphagram);\n",
    "\n",
    "new_sevens_first_update = additions_to_existing_alphagrams('./7snew_owl2_america.txt')\n",
    "new_sevens_second_update = additions_to_existing_alphagrams('./7snew_america_nwl18.txt')\n",
    "new_eights_first_update = additions_to_existing_alphagrams('./8snew_owl2_america.txt')\n",
    "new_eights_second_update = additions_to_existing_alphagrams('./8snew_america_nwl18.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "better_toughies.loc[better_toughies['Alphagram'] == 'ACCEORST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_toughies.loc[better_toughies['Alphagram'] == 'AEELLMSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asked_7s = set()\n",
    "asked_8s = set()\n",
    "\n",
    "# Start at the first lexicon.\n",
    "last_lex = 'OWL2'\n",
    "for row in better_toughies.itertuples():\n",
    "    # row 0 is the index.\n",
    "    lex = row[6]\n",
    "    # Clear out questions that got new additions.\n",
    "    if lex != last_lex:\n",
    "        if lex == 'America':\n",
    "            for alpha in new_sevens_first_update:\n",
    "                if alpha in asked_7s:\n",
    "                    asked_7s.remove(alpha)\n",
    "            for alpha in new_eights_first_update:\n",
    "                if alpha in asked_8s:\n",
    "                    asked_8s.remove(alpha)\n",
    "        elif lex == 'NWL18':\n",
    "            for alpha in new_sevens_second_update:\n",
    "                if alpha in asked_7s:\n",
    "                    asked_7s.remove(alpha)\n",
    "            for alpha in new_eights_second_update:\n",
    "                if alpha in asked_8s:\n",
    "                    asked_8s.remove(alpha) \n",
    "            \n",
    "    alpha = row[1]\n",
    "    if len(alpha) == 7:\n",
    "        asked_7s.add(alpha)\n",
    "    if len(alpha) == 8:\n",
    "        asked_8s.add(alpha) \n",
    "        \n",
    "    last_lex = lex\n",
    "        \n",
    "print(f'Asked {len(asked_7s)} out of {len(alphas_7s)} 7s')\n",
    "print(f'Asked {len(asked_8s)} out of {len(alphas_8s)} 8s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((len(alphas_7s) - len(asked_7s)) / 50)\n",
    "print((len(alphas_8s) - len(asked_8s)) / 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine a list of all bingos by difficulty!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default to taking results for newer lexica. This is because Aerolith may at first have been \n",
    "# populated by people who were already really good at the bingos, but as time passed, more lower-rated\n",
    "# players have been joining. \n",
    "bingos = {}\n",
    "accuracy_limit = 35\n",
    "for row in better_toughies.itertuples():\n",
    "    # Since the df is sorted from oldest to newest lexicon, results from newer \"asks\" will supersede\n",
    "    # older asks, if the number of asks is significantly bigger. If both numbers are above ~80, default\n",
    "    # to the newer value.\n",
    "    alpha = row[1]\n",
    "    if alpha not in bingos or row[3] > bingos[alpha][3] or (\n",
    "            # maybe we don't have as much new data as we have old data, but since new\n",
    "            # data is still probably better, take it anyway if it's above some limit.\n",
    "            bingos[alpha][3] >= accuracy_limit and row[3] >= accuracy_limit):\n",
    "        # Add if it doesn't exist, or if it exists and \n",
    "        # the number of asks is now bigger (more data is\n",
    "        # better). This still might have some bias from\n",
    "        # early Aerolith users being better on average,\n",
    "        # if a question was asked a lot back in the day.\n",
    "        bingos[alpha] = row\n",
    "\n",
    "print(len(bingos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = pandas.DataFrame.from_dict(bingos, orient='index')\n",
    "bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now we can ask some questions. For example, what are the hardest 1000 bingos with probability < 15000?\n",
    "\n",
    "total = 1000\n",
    "prob_limit = 15000\n",
    "alphas = bdf[bdf['probability'] <= prob_limit].sort_values('difficulty', ascending=False)['Alphagram'][:total]\n",
    "ct = 0\n",
    "for alpha in alphas:\n",
    "    if len(alpha) == 7:\n",
    "        ct += 1\n",
    "print(f'There are {ct} 7s out of {total}')\n",
    "# for alpha in alphas:\n",
    "#     print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sevens = bdf.loc[(bdf['Alphagram'].str.len() == 7)].copy()\n",
    "eights = bdf.loc[(bdf['Alphagram'].str.len() == 8)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sevens_hist = sevens.hist(column='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eights_hist = eights.hist(column='difficulty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sevens['difficulty'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eights['difficulty'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    print(f'Quantile {i/10}')\n",
    "    print(sevens.difficulty.quantile(i/10))\n",
    "    print(eights.difficulty.quantile(i/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the above quantile data, we will set some arbitrary cutoffs here:\n",
    "- 10-star bingos: > 60%\n",
    "- 9-star bingos: 52%\n",
    "- 8-star bingos: 46%\n",
    "- 7-star bingos: 40%\n",
    "- 6-star bingos: 34%\n",
    "- 5-star bingos: 28%\n",
    "- 4-star bingos: 22%\n",
    "- 3-star bingos: 15%\n",
    "- 2-star bingos: 10%\n",
    "- 1-star bingos: < 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_to_stars(perc):\n",
    "    cutoffs = [0.1, 0.15, 0.22, 0.28, 0.34, 0.4, 0.46, 0.52, 0.6]\n",
    "    for idx, c in enumerate(cutoffs):\n",
    "        if perc < c:\n",
    "            return idx +1\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eights['difficulty_stars'] = eights['difficulty'].apply(perc_to_stars)\n",
    "sevens['difficulty_stars'] = sevens['difficulty'].apply(perc_to_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sevens = sevens.sort_values('difficulty').reset_index(drop=True)\n",
    "eights = eights.sort_values('difficulty').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create output lists with alphagrams / difficulties\n",
    "with open('sevens_diff.csv', 'w') as f:\n",
    "    sevens.to_csv(f, index=False, columns=['Alphagram', 'difficulty', 'difficulty_stars'])\n",
    "with open('eights_diff.csv', 'w') as f:\n",
    "    eights.to_csv(f, index=False, columns=['Alphagram', 'difficulty', 'difficulty_stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to determine which questions are left to ask (maybe can use for future updates or CSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_8s = list(alphas_8s - asked_8s)\n",
    "missing_7s = list(alphas_7s - asked_7s)\n",
    "\n",
    "asked_7s_new = list(asked_7s)\n",
    "asked_8s_new = list(asked_8s)\n",
    "random.shuffle(asked_7s_new)\n",
    "random.shuffle(asked_8s_new)\n",
    "\n",
    "# Extend the 8s by 23 questions so we have 400 exactly.\n",
    "missing_8s.extend(asked_8s_new[:43])\n",
    "# Extend the 7s so we have 200 exactly\n",
    "missing_7s.extend(asked_7s_new[:103])\n",
    "assert(len(missing_7s) == 200)\n",
    "assert(len(missing_8s) == 400)\n",
    "\n",
    "random.shuffle(missing_7s)\n",
    "random.shuffle(missing_8s)\n",
    "\n",
    "i = 0\n",
    "for seven in missing_7s:\n",
    "    print(seven)\n",
    "    i += 1\n",
    "    if i % 50 == 0:\n",
    "        print('-' * 6)\n",
    "\n",
    "print ('-' * 12)\n",
    "i = 0\n",
    "for eight in missing_8s:\n",
    "    print(eight)\n",
    "    i += 1\n",
    "    if i % 50 == 0:\n",
    "        print('-' * 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge simulator - how many unasked questions do we have after a certain time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_days = 8 * 365   # We've been asking qs for roughly 8 years (since Jun 2011 -- update if changes)\n",
    "num_qs = 50\n",
    "num_alphas = 28029   # How many sevens or eights\n",
    "\n",
    "alphas = set(range(num_alphas))\n",
    "\n",
    "for i in range(num_days):\n",
    "    todays = list(range(num_alphas))\n",
    "    random.shuffle(todays)\n",
    "    for q in todays[:num_qs]:\n",
    "        if q in alphas:\n",
    "            alphas.remove(q)\n",
    "\n",
    "print(len(alphas))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
